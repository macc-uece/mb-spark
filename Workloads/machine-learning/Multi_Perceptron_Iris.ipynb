{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spark Lib\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "#import pyarrow\n",
    "\n",
    "## SKLearn Lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset file\n",
    "#data_path='/data/biodata/Iris/'\n",
    "%store -r path\n",
    "\n",
    "# Sample of train and test dataset\n",
    "train_sample = 0.7\n",
    "test_sample = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network and SVM using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[8]\") \\\n",
    "        .appName(\"MachineLearningIris\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "#spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe read from CSV file\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal length|sepal width|petal length|petal width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Iris CSV dataset to Spark Dataframe\n",
    "orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "            load(path)\n",
    "\n",
    "print(\"Original Dataframe read from CSV file\")\n",
    "#orig_data.dtypes\n",
    "orig_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classifier Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with numeric lable\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|sepal length|sepal width|petal length|petal width|      class|label|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ML libraries doesn't accept string column => everything should be numeric! \n",
    "# create a numeric column \"label\" based on string column \"class\" \n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(orig_data)\n",
    "label_data = indexer.transform(orig_data)\n",
    "\n",
    "# Save the inverse map from numeric \"label\" to string \"class\" to be used further in response\n",
    "labelReverse = IndexToString().setInputCol(\"label\")\n",
    "\n",
    "# Show labeled dataframe with numeric lable\n",
    "print(\"Dataframe with numeric lable\")\n",
    "label_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataframe suitable to classifier input format\n",
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop string column \"class\", no string column\n",
    "label_data = label_data.drop(\"class\")\n",
    "\n",
    "# Most Machine Learning Lib inpute 2 columns: label (output) and feature (input)\n",
    "# The label column is the result to train ML algorithm \n",
    "# The feature column should join all parameters as a Vector\n",
    "\n",
    "# Set the column names that is not part of features list\n",
    "ignore = ['label']\n",
    "# list will be all columns parts of features\n",
    "list = [x for x in label_data.columns if x not in ignore]\n",
    "\n",
    "# VectorAssembler mount the vector of features\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=list,\n",
    "            outputCol='features')\n",
    "\n",
    "# Create final dataframe composed by label and a column of features vector\n",
    "data = (assembler.transform(label_data).select(\"label\",\"features\"))\n",
    "\n",
    "print(\"Final Dataframe suitable to classifier input format\")\n",
    "#data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ramdomly the dataset into train and test group\n",
    "# [0.7,0.3] => 70% for train and 30% for test\n",
    "# [1.0,0.2] => 100% for train and 20% for test, not good, acuracy always 100%\n",
    "# [0.1,0.02] => 10% for train and 2% for test, if big datasets\n",
    "# 1234 is the random seed\n",
    "\n",
    "(train, test) = data.randomSplit([train_sample, test_sample], 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Final Result\n",
      "+-----+-----------------+--------------------+--------------------+----------+\n",
      "|label|         features|       rawPrediction|         probability|prediction|\n",
      "+-----+-----------------+--------------------+--------------------+----------+\n",
      "|  0.0|[4.3,3.0,1.1,0.1]|[125.163773163649...|[1.0,7.0597849525...|       0.0|\n",
      "|  0.0|[4.4,2.9,1.4,0.2]|[125.156306784322...|[1.0,7.1231710288...|       0.0|\n",
      "|  0.0|[4.4,3.0,1.3,0.2]|[125.163112010735...|[1.0,7.0653749965...|       0.0|\n",
      "|  0.0|[4.8,3.1,1.6,0.2]|[125.153911586500...|[1.0,7.1436254650...|       0.0|\n",
      "|  0.0|[5.0,3.5,1.6,0.6]|[125.164148267820...|[1.0,7.0566154156...|       0.0|\n",
      "+-----+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time_pr =  time.time()\n",
    "# specify layers for the neural network\n",
    "# parameter 1: input layer, should be the number of features\n",
    "# parameter 2 and 3: the number os perceptron in two intermediate layers\n",
    "# parameter 4: output layer should be the number os categories (labels)\n",
    "layers = [4, 5, 5, 3]\n",
    "\n",
    "# Create the trainer and set its parameters\n",
    "# featuresCol=name_feature_column, labelCol=name_label_column\n",
    "# maxIter=max_interaction, layers=list_number_perceptron \n",
    "\n",
    "trainer = MultilayerPerceptronClassifier(featuresCol='features', labelCol='label',\\\n",
    "          maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model and get the result\n",
    "model = trainer.fit(train)\n",
    "result_pr = model.transform(test)\n",
    "\n",
    "print(\"Perceptron Final Result\")\n",
    "result_pr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron: accuracy = 97.5 %\n",
      "Multilayer Perceptron: time = 6.031 s\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set against model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "            metricName=\"accuracy\")\n",
    "\n",
    "accuracy_pr = evaluator.evaluate(result_pr) * 100\n",
    "time_pr = time.time() - start_time_pr\n",
    "\n",
    "print(\"Multilayer Perceptron: accuracy = %3.1f %%\" % accuracy_pr)\n",
    "print(\"Multilayer Perceptron: time = %3.3f s\" % time_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron final result with name of class\n",
      "+-----+-----------------+--------------------+--------------------+----------+----------------------------------+\n",
      "|label|         features|       rawPrediction|         probability|prediction|IndexToString_7f4f1ca1ab75__output|\n",
      "+-----+-----------------+--------------------+--------------------+----------+----------------------------------+\n",
      "|  0.0|[4.3,3.0,1.1,0.1]|[125.163773163649...|[1.0,7.0597849525...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[4.4,2.9,1.4,0.2]|[125.156306784322...|[1.0,7.1231710288...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[4.4,3.0,1.3,0.2]|[125.163112010735...|[1.0,7.0653749965...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[4.8,3.1,1.6,0.2]|[125.153911586500...|[1.0,7.1436254650...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.0,3.5,1.6,0.6]|[125.164148267820...|[1.0,7.0566154156...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|[125.164150423534...|[1.0,7.0565972045...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.1,3.5,1.4,0.3]|[125.164127051884...|[1.0,7.0567946470...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.1,3.8,1.6,0.2]|[125.164155045067...|[1.0,7.0565581627...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.2,4.1,1.5,0.1]|[125.164156275570...|[1.0,7.0565477677...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.4,3.4,1.7,0.2]|[125.158208844617...|[1.0,7.1069696029...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.4,3.9,1.7,0.4]|[125.164155416783...|[1.0,7.0565550225...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.5,3.5,1.3,0.2]|[125.163804789322...|[1.0,7.0595176685...|       0.0|                       Iris-setosa|\n",
      "|  0.0|[5.7,3.8,1.7,0.3]|[125.164112690862...|[1.0,7.0569159710...|       0.0|                       Iris-setosa|\n",
      "|  1.0|[5.0,2.3,3.3,1.0]|[-4.4844053136379...|[9.62819208320372...|       1.0|                   Iris-versicolor|\n",
      "|  1.0|[5.6,2.7,4.2,1.3]|[-4.4844053199281...|[9.62819197503780...|       1.0|                   Iris-versicolor|\n",
      "|  1.0|[5.6,3.0,4.5,1.5]|[-4.4843160900634...|[9.62975819388208...|       1.0|                   Iris-versicolor|\n",
      "|  1.0|[5.9,3.0,4.2,1.5]|[-4.4843797521913...|[9.62863892547216...|       1.0|                   Iris-versicolor|\n",
      "|  1.0|[6.0,2.9,4.5,1.5]|[-4.4844052696211...|[9.62819284025216...|       1.0|                   Iris-versicolor|\n",
      "|  1.0|[6.0,3.4,4.5,1.6]|[89.7328577171872...|[1.0,1.8618174832...|       0.0|                   Iris-versicolor|\n",
      "|  1.0|[6.1,2.8,4.7,1.2]|[-4.4844054342235...|[9.62819001052218...|       1.0|                   Iris-versicolor|\n",
      "+-----+-----------------+--------------------+--------------------+----------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Perceptron final result with name of class\")\n",
    "labelReverse.transform(result_pr).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
