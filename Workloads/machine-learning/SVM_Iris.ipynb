{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spark Lib\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "#import pyarrow\n",
    "\n",
    "## SKLearn Lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset file\n",
    "#data_path='/data/biodata/Iris/'\n",
    "%store -r path\n",
    "\n",
    "# Sample of train and test dataset\n",
    "train_sample = 0.7\n",
    "test_sample = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[8]\") \\\n",
    "        .appName(\"MachineLearningIris\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "#spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe read from CSV file\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal length|sepal width|petal length|petal width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Iris CSV dataset to Spark Dataframe\n",
    "orig_data = spark.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "            load(path)\n",
    "\n",
    "print(\"Original Dataframe read from CSV file\")\n",
    "#orig_data.dtypes\n",
    "orig_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with numeric lable\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|sepal length|sepal width|petal length|petal width|      class|label|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ML libraries doesn't accept string column => everything should be numeric! \n",
    "# create a numeric column \"label\" based on string column \"class\" \n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(orig_data)\n",
    "label_data = indexer.transform(orig_data)\n",
    "\n",
    "# Save the inverse map from numeric \"label\" to string \"class\" to be used further in response\n",
    "labelReverse = IndexToString().setInputCol(\"label\")\n",
    "\n",
    "# Show labeled dataframe with numeric lable\n",
    "print(\"Dataframe with numeric lable\")\n",
    "label_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataframe suitable to classifier input format\n",
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop string column \"class\", no string column\n",
    "label_data = label_data.drop(\"class\")\n",
    "\n",
    "# Most Machine Learning Lib inpute 2 columns: label (output) and feature (input)\n",
    "# The label column is the result to train ML algorithm \n",
    "# The feature column should join all parameters as a Vector\n",
    "\n",
    "# Set the column names that is not part of features list\n",
    "ignore = ['label']\n",
    "# list will be all columns parts of features\n",
    "list = [x for x in label_data.columns if x not in ignore]\n",
    "\n",
    "# VectorAssembler mount the vector of features\n",
    "assembler = VectorAssembler(\n",
    "            inputCols=list,\n",
    "            outputCol='features')\n",
    "\n",
    "# Create final dataframe composed by label and a column of features vector\n",
    "data = (assembler.transform(label_data).select(\"label\",\"features\"))\n",
    "\n",
    "print(\"Final Dataframe suitable to classifier input format\")\n",
    "#data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ramdomly the dataset into train and test group\n",
    "# [0.7,0.3] => 70% for train and 30% for test\n",
    "# [1.0,0.2] => 100% for train and 20% for test, not good, acuracy always 100%\n",
    "# [0.1,0.02] => 10% for train and 2% for test, if big datasets\n",
    "# 1234 is the random seed\n",
    "\n",
    "(train, test) = data.randomSplit([train_sample, test_sample], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_svm =  time.time()\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = LinearSVC(featuresCol='features', labelCol='label',\\\n",
    "                    maxIter=100, regParam=0.1)\n",
    "\n",
    "# LinearSVC classify ONLY in two classes\n",
    "# To classify in more than 2 classes, the OneVsrest should be used\n",
    "# Cloud use any kind of classifies\n",
    "\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr_trainer = OneVsRest(classifier=trainer)\n",
    "\n",
    "# train the multiclass model.\n",
    "model = ovr_trainer.fit(train)\n",
    "\n",
    "# score the model on test data.\n",
    "result_svm = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suport Vector Machines (SVM): accuracy = 65.0 %\n",
      "Suport Vector Machines (SVM): time = 47.851 s\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set against model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "            metricName=\"accuracy\")\n",
    "\n",
    "accuracy_svm = evaluator.evaluate(result_svm) * 100\n",
    "time_svm = time.time() - start_time_svm\n",
    "\n",
    "print(\"Suport Vector Machines (SVM): accuracy = %3.1f %%\" % accuracy_svm)\n",
    "print(\"Suport Vector Machines (SVM): time = %3.3f s\" % time_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suport Vector Machines (SVM) Final Result\n",
      "+-----+-----------------+----------+\n",
      "|label|         features|prediction|\n",
      "+-----+-----------------+----------+\n",
      "|  0.0|[4.3,3.0,1.1,0.1]|       0.0|\n",
      "|  0.0|[4.4,2.9,1.4,0.2]|       0.0|\n",
      "|  0.0|[4.4,3.0,1.3,0.2]|       0.0|\n",
      "|  0.0|[4.8,3.1,1.6,0.2]|       0.0|\n",
      "|  0.0|[5.0,3.5,1.6,0.6]|       0.0|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "|  0.0|[5.1,3.5,1.4,0.3]|       0.0|\n",
      "|  0.0|[5.1,3.8,1.6,0.2]|       0.0|\n",
      "|  0.0|[5.2,4.1,1.5,0.1]|       0.0|\n",
      "|  0.0|[5.4,3.4,1.7,0.2]|       0.0|\n",
      "|  0.0|[5.4,3.9,1.7,0.4]|       0.0|\n",
      "|  0.0|[5.5,3.5,1.3,0.2]|       0.0|\n",
      "|  0.0|[5.7,3.8,1.7,0.3]|       0.0|\n",
      "|  1.0|[5.0,2.3,3.3,1.0]|       1.0|\n",
      "|  1.0|[5.6,2.7,4.2,1.3]|       2.0|\n",
      "|  1.0|[5.6,3.0,4.5,1.5]|       2.0|\n",
      "|  1.0|[5.9,3.0,4.2,1.5]|       2.0|\n",
      "|  1.0|[6.0,2.9,4.5,1.5]|       2.0|\n",
      "|  1.0|[6.0,3.4,4.5,1.6]|       2.0|\n",
      "|  1.0|[6.1,2.8,4.7,1.2]|       2.0|\n",
      "+-----+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Suport Vector Machines (SVM) Final Result\")\n",
    "result_svm.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
